{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pymdptoolbox"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "from scipy import sparse\n",
    "import mdptoolbox\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Warehouse Settings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse Size: 4\n",
      "Warehouse Actions: store, restore\n",
      "Block Types:  empty, red, blue, white\n"
     ]
    }
   ],
   "source": [
    "warehouse_dim_x = 2\n",
    "warehouse_dim_y = 2\n",
    "warehouse_actions = ['store', 'restore']\n",
    "warehouse_blocktypes = ['empty', 'red', 'blue', 'white']\n",
    "warehouse_size = warehouse_dim_x * warehouse_dim_y\n",
    "\n",
    "print(\"Warehouse Size:\", warehouse_size)\n",
    "print(\"Warehouse Actions:\", \", \".join(warehouse_actions))\n",
    "print(\"Block Types: \", \", \".join(warehouse_blocktypes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 24216\n",
      "Testset Size: 120\n",
      "    action blocktype\n",
      "0    store       red\n",
      "1    store      blue\n",
      "2    store     white\n",
      "3  restore      blue\n",
      "4  restore     white\n"
     ]
    }
   ],
   "source": [
    "training_data = pd.read_csv('./res/warehousetraining.txt', sep=\"\\t\", names=['action', 'blocktype'])\n",
    "print(\"Dataset Size:\", training_data.size)\n",
    "test_data = pd.read_csv('./res/warehouseorder.txt', sep=\"\\t\", names=['action', 'blocktype'])\n",
    "print(\"Testset Size:\", test_data.size)\n",
    "\n",
    "print(training_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single Probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2897\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2898\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2899\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-28-fac1d454837a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mprobability_map\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mstore_white\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraining_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'store'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m&\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'white'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[0mstore_blue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraining_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'store'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m&\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'blue'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mstore_red\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraining_data\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'store'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m&\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'red'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2904\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2905\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2906\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2907\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2908\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2898\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcasted_key\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2899\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2900\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0merr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2901\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2902\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mtolerance\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "source": [
    "df = training_data.copy()\n",
    "df = training_data.groupby([\"action\", \"blocktype\"]).size().reset_index(name='probability')\n",
    "training_data['probability'] = df['probability'].div(df.size)\n",
    "\n",
    "probability_map = dict()\n",
    "\n",
    "store_white = training_data.loc[(training_data[0] == 'store') & (training_data[1] == 'white')]\n",
    "store_blue = training_data.loc[(training_data[0] == 'store') & (training_data[1] == 'blue')]\n",
    "store_red = training_data.loc[(training_data[0] == 'store') & (training_data[1] == 'red')]\n",
    "\n",
    "restore_white = training_data.loc[(training_data[0] == 'restore') & (training_data[1] == 'white')]\n",
    "restore_blue = training_data.loc[(training_data[0] == 'restore') & (training_data[1] == 'blue')]\n",
    "restore_red = training_data.loc[(training_data[0] == 'restore') & (training_data[1] == 'red')]\n",
    "\n",
    "probability_map[('store', 'white')] = store_white.size / training_data.size\n",
    "probability_map[('store', 'blue')] = store_blue.size / training_data.size\n",
    "probability_map[('store', 'red')] = store_red.size / training_data.size\n",
    "probability_map[('restore', 'white')] = restore_white.size / training_data.size\n",
    "probability_map[('restore', 'blue')] = restore_blue.size / training_data.size\n",
    "probability_map[('restore', 'red')] = restore_red.size / training_data.size\n",
    "\n",
    "print(\"Store White: \", probability_map[('store', 'white')])\n",
    "print(\"Store Red: \", probability_map[('store', 'blue')])\n",
    "print(\"Store Blue: \", probability_map[('store', 'red')])\n",
    "\n",
    "print(\"\\nRestore White: \", probability_map[('restore', 'white')])\n",
    "print(\"Restore Red: \", probability_map[('restore', 'blue')])\n",
    "print(\"Restore Blue: \", probability_map[('restore', 'red')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Warehouse States"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 6 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_list_to_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    563\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 564\u001B[1;33m         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_validate_or_indexify_columns\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    565\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_object_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_validate_or_indexify_columns\u001B[1;34m(content, columns)\u001B[0m\n\u001B[0;32m    688\u001B[0m             raise AssertionError(\n\u001B[1;32m--> 689\u001B[1;33m                 \u001B[1;34mf\"{len(columns)} columns passed, passed data had \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    690\u001B[0m                 \u001B[1;34mf\"{len(content)} columns\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: 7 columns passed, passed data had 6 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-25-327febbd9af2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[0mwarehouse_dataframe_columns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"probability\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m \u001B[0mwarehouse_dataframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitertools\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mproduct\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwarehouse_blocktypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarehouse_blocktypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarehouse_blocktypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarehouse_blocktypes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarehouse_actions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarehouse_blocktypes_without_empty\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mwarehouse_dataframe_columns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[0mwarehouse_dataframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmerge\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwarehouse_dataframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprobability_map\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mon\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"action\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"blocktype\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    507\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0mis_named_tuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    508\u001B[0m                         \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fields\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 509\u001B[1;33m                     \u001B[0marrays\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    510\u001B[0m                     \u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    522\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m  \u001B[1;31m# columns if columns is not None else []\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 524\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_list_to_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    525\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mabc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mMapping\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    526\u001B[0m         return _list_of_dict_to_arrays(\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001B[0m in \u001B[0;36m_list_to_arrays\u001B[1;34m(data, columns, coerce_float, dtype)\u001B[0m\n\u001B[0;32m    565\u001B[0m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_convert_object_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcoerce_float\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcoerce_float\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    566\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mAssertionError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 567\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    568\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: 7 columns passed, passed data had 6 columns"
     ]
    }
   ],
   "source": [
    "warehouse_blocktypes_without_empty = list(warehouse_blocktypes)\n",
    "if 'empty' in warehouse_blocktypes_without_empty:\n",
    "    warehouse_blocktypes_without_empty.remove('empty')\n",
    "\n",
    "warehouse_moves = list(itertools.product(warehouse_actions, warehouse_blocktypes_without_empty)) # We ignore the empty block type\n",
    "\n",
    "warehouse_states = list(itertools.product(warehouse_blocktypes, repeat=warehouse_size))\n",
    "warehouse_action_states = list(itertools.product(warehouse_states, warehouse_actions))\n",
    "\n",
    "warehouse_dataframe_columns = []\n",
    "for field in range(warehouse_size):\n",
    "    warehouse_dataframe_columns.append(\"field \"+str(field))\n",
    "warehouse_dataframe_columns.append(\"action\")\n",
    "warehouse_dataframe_columns.append(\"object\")\n",
    "warehouse_dataframe_columns.append(\"probability\")\n",
    "\n",
    "warehouse_dataframe = pd.DataFrame(list(itertools.product(warehouse_blocktypes, warehouse_blocktypes, warehouse_blocktypes, warehouse_blocktypes, warehouse_actions, warehouse_blocktypes_without_empty)), columns=warehouse_dataframe_columns)\n",
    "warehouse_dataframe = pd.merge(warehouse_dataframe, probability_map, on=[\"action\", \"blocktype\"])\n",
    "\n",
    "print(warehouse_dataframe.head())\n",
    "print(\"Possible Moves:\\n\", warehouse_moves)\n",
    "print(\"States:\", len(warehouse_action_states))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transition Probability Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished P0\n",
      "finished P1\n",
      "finished P2\n",
      "finished P3\n"
     ]
    }
   ],
   "source": [
    "transition_probability_matrix = []\n",
    "block_size = len(warehouse_blocktypes) ** warehouse_size\n",
    "\n",
    "number_of_warehouse_fields = warehouse_size\n",
    "for action in range(number_of_warehouse_fields):\n",
    "    current_index = 0\n",
    "    transition_probability_matrix.append(np.zeros((len(warehouse_action_states), len(warehouse_action_states)),dtype=np.float16))\n",
    "\n",
    "    for order in range(len(warehouse_moves)):\n",
    "        for warehouse_state in itertools.product(warehouse_blocktypes, repeat=warehouse_size):\n",
    "           for move in warehouse_moves:\n",
    "\n",
    "                if(warehouse_state[action] != 'empty'):\n",
    "                    transition_probability_matrix[action][current_index][(current_index % block_size) + (block_size * warehouse_moves.index(move))] = probability_map[move]\n",
    "                else:\n",
    "                    transition_probability_matrix[action][current_index][((current_index % block_size) + (len(warehouse_blocktypes)**(number_of_warehouse_fields - action - 1) * warehouse_blocktypes.index(move[1]))) + (block_size * warehouse_moves.index(move))] = probability_map[move]\n",
    "           current_index += 1\n",
    "\n",
    "    transition_probability_matrix[action] = sparse.csr_matrix(transition_probability_matrix[action])\n",
    "    print(\"finished P\"+str(action))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled TPM\n"
     ]
    }
   ],
   "source": [
    "pickle.dump( P, open( \"./res/P.pickle\", \"wb\" ) )\n",
    "print(\"Pickled TPM\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reward Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reward_matrix = []\n",
    "\n",
    "for action in range(number_of_warehouse_fields):\n",
    "    reward_matrix.append(np.zeros((len(warehouse_action_states), len(warehouse_action_states)),dtype=np.float16))\n",
    "\n",
    "    for (state, action) in warehouse_action_states:\n",
    "        try:\n",
    "            (actiontype, blocktype) = action\n",
    "            #Reward for correct move\n",
    "            if((actiontype == 'store' and state[action] == 0) or\n",
    "            (actiontype == 'restore' and (state[action] == (ws.NextMove - 2)))):\n",
    "\n",
    "                if  (action == 0): reward = 80**2  #8**3.5;\n",
    "                elif(action == 1): reward = 60**2  #6**3.5;\n",
    "                elif(action == 2): reward = 60**2  #6**3.5;\n",
    "                elif(action == 3): reward = 40**2  #4**3.5;\n",
    "                elif(action == 4): reward = 40**2  #4**3.5;\n",
    "                elif(action == 5): reward = 40**2  #2**3.5;\n",
    "\n",
    "                #Extra reward if restore is possible\n",
    "                if actiontype == 'restore' and (ws[action] == (ws.NextMove - 2)):\n",
    "                    reward *= 100  #+=100\n",
    "\n",
    "            #Reward for Failed moves\n",
    "            else:\n",
    "                #store not possible\n",
    "                if actiontype == 'store':\n",
    "                    reward = -20000  #5\n",
    "                #restore not possible\n",
    "                else:\n",
    "                    reward = -1000000  #-10\n",
    "\n",
    "            reward_matrix[-1][index] = reward\n",
    "\n",
    "\n",
    "\n",
    "reward_matrix = np.asarray(reward_matrix)\n",
    "reward_matrix = reward_matrix.transpose()\n",
    "\n",
    "# Save the matrices into a pickle file.\n",
    "pickle.dump(reward_matrix, open( \"./res/reward_matrix.pickle\", \"wb\" ) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished P0\n",
      "finished P1\n",
      "finished P2\n",
      "finished P3\n",
      "---\n",
      "successfull\n",
      "   state0  state1  state2  state3  NextMove\n",
      "0       0       0       0       0         0\n",
      "1       0       0       0       1         0\n",
      "2       0       0       0       2         0\n",
      "3       0       0       0       3         0\n",
      "4       0       0       1       0         0\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "num_fields = 4 # Warehouse places 2x2 = 4 ..\n",
    "############################################\n",
    "\n",
    "num_color = 4 # empty, red, white,\n",
    "# blue\n",
    "num_moves = 6 # store red, store white, store blue, restore red, ...\n",
    "num_actions = num_fields\n",
    "block_size = num_color ** num_fields\n",
    "\n",
    "num_state = num_color ** num_fields * num_moves\n",
    "warehouse_description=[0,1,2,3] #possible colors\n",
    "\n",
    "#Init TPM\n",
    "P = []\n",
    "\n",
    "move_probs = [\n",
    "    0.1278493557978196,\n",
    "    0.12528906508093823,\n",
    "    0.24686157912124215,\n",
    "    0.1278493557978196,\n",
    "    0.12528906508093823,\n",
    "    0.24686157912124215\n",
    "]\n",
    "\n",
    "for action in range(num_actions):\n",
    "    current_index = 0\n",
    "    P.append(np.zeros((num_state, num_state),dtype=np.float16))\n",
    "\n",
    "    for instr in range(num_moves):\n",
    "        for w_state in itertools.product(warehouse_description, repeat=num_fields):\n",
    "            #Iter through all 6 column blocks (=possible instructions) (store red, store blue, ...., restore red, ...)\n",
    "            for move in range(num_moves):\n",
    "\n",
    "                ##For field one (Action)\n",
    "                #FOR STORE\n",
    "                if(instr in range(3)):\n",
    "\n",
    "                    #1. Empty? if (field1 == 0)\n",
    "                    if(w_state[action] != 0):\n",
    "                        P[action][current_index][(current_index % block_size) + (block_size * move)] = move_probs[move]\n",
    "                    else:\n",
    "                        #FOR STORE\n",
    "                        #if(red) index+64 (i**numFields)\n",
    "                        # else if(white) index+128\n",
    "                        # else if(blue) index+192\n",
    "\n",
    "                        #red = 0\n",
    "                        if(instr == 0):\n",
    "                            P[action][current_index][((current_index % block_size) + (num_color**(num_actions - action - 1) * 1)) + (block_size * move)] = move_probs[move]\n",
    "                        #white = 1\n",
    "                        elif(instr == 1):\n",
    "                            P[action][current_index][((current_index % block_size) + (num_color**(num_actions - action - 1) * 2)) + (block_size * move)] = move_probs[move]\n",
    "                        #blue = 2\n",
    "                        elif(instr == 2):\n",
    "                            P[action][current_index][((current_index % block_size) + (num_color**(num_actions - action - 1) * 3)) + (block_size * move)] = move_probs[move]\n",
    "\n",
    "\n",
    "                #FOR RESTORE\n",
    "                else:\n",
    "                    #possible? if (field 1 != 0)\n",
    "                    if(w_state[action] == 0):\n",
    "                        P[action][current_index][(current_index % block_size) + (block_size * move)] = move_probs[move]\n",
    "                    else:\n",
    "                        #FOR STORE\n",
    "                        #if(red) index-64 (i**numFields)\n",
    "                        # else if(white) index-128\n",
    "                        # else if(blue) index-192\n",
    "\n",
    "                        #red = 3\n",
    "                        if(instr == 3):\n",
    "                            P[action][current_index][((current_index % block_size) - (num_color**(num_actions - action - 1) * 1)) + (block_size * move)] = move_probs[move]\n",
    "                        #white = 4\n",
    "                        elif(instr == 4):\n",
    "                            P[action][current_index][((current_index % block_size) - (num_color**(num_actions - action - 1) * 2)) + (block_size * move)] = move_probs[move]\n",
    "                        #blue = 5\n",
    "                        elif(instr == 5):\n",
    "                            P[action][current_index][((current_index % block_size) - (num_color**(num_actions - action - 1) * 3)) + (block_size * move)] = move_probs[move]\n",
    "\n",
    "            current_index += 1\n",
    "\n",
    "    P[action] = sparse.csr_matrix(P[action])\n",
    "    print(\"finished P\"+str(action))\n",
    "\n",
    "print(\"---\")\n",
    "print(\"successfull\")\n",
    "\n",
    "warehouse = []\n",
    "for instr in range(num_moves):\n",
    "    for w_state in itertools.product(warehouse_description, repeat=num_fields):\n",
    "        tmp = []\n",
    "        tmp_str = []\n",
    "        for i in range(num_fields):\n",
    "            tmp.append(w_state[i])\n",
    "            tmp_str.append('state'+str(i))\n",
    "        tmp.append(instr)\n",
    "        tmp_str.append('NextMove')\n",
    "        warehouse.append(tmp)\n",
    "\n",
    "warehouse = pd.DataFrame(warehouse, columns=tmp_str)\n",
    "print(warehouse.head())\n",
    "\n",
    "R = []\n",
    "\n",
    "for action in range(num_actions):\n",
    "    R.append(np.zeros((num_state, )))\n",
    "\n",
    "    for index, ws in warehouse.iterrows():\n",
    "        try:\n",
    "            #Reward for correct move\n",
    "            if((ws.NextMove in range(3) and ws[action] == 0) or\n",
    "            (ws.NextMove in range(3, 6) and (ws[action] == (ws.NextMove - 2)))):\n",
    "\n",
    "                if  (action == 0): reward = 80**2  #8**3.5;\n",
    "                elif(action == 1): reward = 60**2  #6**3.5;\n",
    "                elif(action == 2): reward = 60**2  #6**3.5;\n",
    "                elif(action == 3): reward = 40**2  #4**3.5;\n",
    "                elif(action == 4): reward = 40**2  #4**3.5;\n",
    "                elif(action == 5): reward = 40**2  #2**3.5;\n",
    "\n",
    "                #Extra reward if restore is possible\n",
    "                if ws.NextMove in range(3, 6) and (ws[action] == (ws.NextMove - 2)):\n",
    "                    reward *= 100  #+=100\n",
    "\n",
    "            #Reward for Failed moves\n",
    "            else:\n",
    "                #store not possible\n",
    "                if ws.NextMove in range(3):\n",
    "                    reward = -20000  #5\n",
    "                #restore not possible\n",
    "                else:\n",
    "                    reward = -1000000  #-10\n",
    "\n",
    "            R[-1][index] = reward\n",
    "\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            print(ws.NextMove)\n",
    "            print(ws[action])\n",
    "\n",
    "R = np.asarray(R)\n",
    "R = R.transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify Matrices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "StochasticError",
     "evalue": "'PyMDPToolbox - The transition probability matrix is not stochastic.'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mStochasticError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-094c6449d219>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmdptoolbox\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtransition_probability_matrix\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mR\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\mdptoolbox\\util.py\u001B[0m in \u001B[0;36mcheck\u001B[1;34m(P, R)\u001B[0m\n\u001B[0;32m    292\u001B[0m     \u001B[1;31m# Check that the P's are square, stochastic and non-negative\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    293\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0maa\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maP\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 294\u001B[1;33m         \u001B[0mcheckSquareStochastic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mP\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0maa\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    295\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mgetSpan\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mW\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\VMs\\Anaconda-Env\\env_3_6\\lib\\site-packages\\mdptoolbox\\util.py\u001B[0m in \u001B[0;36mcheckSquareStochastic\u001B[1;34m(matrix)\u001B[0m\n\u001B[0;32m    202\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0m_error\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSquareError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    203\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misStochastic\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 204\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0m_error\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStochasticError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    205\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misNonNegative\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0m_error\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNonNegativeError\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mStochasticError\u001B[0m: 'PyMDPToolbox - The transition probability matrix is not stochastic.'"
     ]
    }
   ],
   "source": [
    "mdptoolbox.util.check(transition_probability_matrix,R)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def store_next_states_df(state_now, place):\n",
    "    df_pos = states\n",
    "    if state_now[place] == '0':\n",
    "        for i in storage_places:\n",
    "            if (i == place):\n",
    "                df_pos = df_pos.loc[df_pos.iloc[ : , i-1]== row [size_storage+2]]\n",
    "            else:\n",
    "                df_pos = df_pos.loc[df_pos.iloc[ : , i-1] == row [i]]\n",
    "    else:\n",
    "        for i in storage_places:\n",
    "            df_pos = df_pos.loc[df_pos.iloc[ : , i-1] == row [i]]\n",
    "    return df_pos\n",
    "\n",
    "def restore_next_states_df(state_now, place):\n",
    "    df_pos = states\n",
    "    if state_now[place] == state_now[size_storage+2]:\n",
    "        for i in storage_places:\n",
    "            if (i == place):\n",
    "                df_pos = df_pos.loc[df_pos.iloc[ : , i-1]== '0']\n",
    "            else:\n",
    "                df_pos = df_pos.loc[df_pos.iloc[ : , i-1] == row [i]]\n",
    "    else:\n",
    "        for i in storage_places:\n",
    "            df_pos = df_pos.loc[df_pos.iloc[ : , i-1] == row [i]]\n",
    "    return df_pos\n",
    "\n",
    "def init_trans_prob_mat(df_next_states, state_now, trans_prob_mat):\n",
    "    for i in df_next_states.index:\n",
    "        trans_prob_mat.itemset((state_now[0],i),round(df_next_states.loc[[i]].probability,4))\n",
    "     return trans_prob_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trans_prob_mat = []\n",
    "trans_prob_mat_all = []\n",
    "\n",
    "for place in storage_places:\n",
    "    trans_prob_mat = np.zeros((len(states),len(states)), dtype=np.float16)\n",
    "    for row in states.itertuples():\n",
    "        #print(row)\n",
    "        df_next_states = []\n",
    "\n",
    "        #an dataframe that stores all the rows where the trans prob mat is not null\n",
    "        if (row[size_storage+1] == 'store'):\n",
    "            df_next_states= store_next_states_df(row,place)\n",
    "            #print(df_next_states)\n",
    "\n",
    "        elif(row[size_storage+1] == 'restore'):\n",
    "            df_next_states= restore_next_states_df(row,place)\n",
    "            #print(df_next_states)\n",
    "\n",
    "        else:\n",
    "            print(\"Wrong Instruction in array\")\n",
    "\n",
    "\n",
    "        trans_prob_mat = init_trans_prob_mat(df_next_states, row, trans_prob_mat)\n",
    "\n",
    "    #print(place)\n",
    "\n",
    "    np.save(\"trans_mat\"+str(place)+\".nyp\", trans_prob_mat)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    trans_prob_mat_all.append(trans_prob_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}